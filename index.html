<!DOCTYPE html>

<head>
    <title>Zoom WebSDK</title>
    <meta charset="utf-8" />
    <meta name="format-detection" content="telephone=no">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
    <meta http-equiv="origin-trial" 
        content="Ajef7HX0RdfwBqZYrUVlvUHsQSXOEQiBvj0Olet0DgYa8gmqo+NB+1sFkxlFPC/dF+UI3qFa9KPqDkhpt25a5AsAAABeeyJvcmlnaW4iOiJodHRwOi8vbG9jYWxob3N0OjgxIiwiZmVhdHVyZSI6IlVucmVzdHJpY3RlZFNoYXJlZEFycmF5QnVmZmVyIiwiZXhwaXJ5IjoxNjg4MDgzMTk5fQ=="
    >
    <!-- The link below is for the mic and camera icons in this demo -->
    <link 
        rel="stylesheet" 
        href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css" 
        integrity="sha512-iBBXm8fW90+nuLcSKlbmrPcLa0OT92xO1BIsZ+ywDWZCvqsWgccV3gFoRBv0z+8dLJgyAHIhR35VZc2oM/gI1w==" 
        crossorigin="anonymous" 
    />
	<link rel="stylesheet" href="index.css" />
	<script src="https://source.zoom.us/videosdk/zoom-video-1.7.0.min.js" as="script"></script>
	 <script src="https://kjur.github.io/jsrsasign/jsrsasign-all-min.js"></script>
	 
</head>

<body>
    <div class="container app-root">
        <!-- Preview view -->
        <div id="js-preview-view" class="container preview__root">
            <span>
                <h1>Join Video Session</h1>
            </span>
            <div class="container video-app">
                <!-- You can use any height or width you wish for the preview -->
                <video id="js-preview-video" class="preview-video" playsinline="" muted="" data-video="0"></video>
                <div class="container meeting-control-layer">
                    <!-- "fas" and "fa" are icon prefixes for the font-awesome library -->
                    <button id="js-preview-mic-button" class="meeting-control-button">
                        <i id="js-preview-mic-icon" class="fas fa-microphone-slash"></i>
                    </button>
                    <button id="js-preview-webcam-button" class="meeting-control-button">
                        <i id="js-preview-webcam-icon" class="fas fa-video webcam__off"></i>
                    </button>
                </div>
            </div>
            <button id="js-preview-join-button" class="join-button">
                Join
            </button>
        </div>
        <!-- Loading view -->
        <div id="js-loading-view" class="container loading-view hidden">
            <h1>Joining session, sit tight...</h1>
            <i class="fas fa-spinner loading-spinner"></i>
        </div>
        <!-- In-session view -->
        <div id="js-video-view" class="container video-app hidden">
            <canvas id="video-canvas" class="video-canvas" width="1280" height="640"></canvas>
            <video id="self-video" class="self-video ! important "></video>
            <canvas id="self-video-canvas" class="self-video-canvas" width="640" height="360"></canvas>
            <div class="container meeting-control-layer">
                <!-- "fas" and "fa" are icon prefixes for the font-awesome library -->
                <button id="js-mic-button" class="meeting-control-button">
                    <i id="js-mic-icon" class="fas fa-microphone-slash"></i>
                </button>
                <button id="js-webcam-button" class="meeting-control-button">
                    <i id="js-webcam-icon" class="fas fa-video webcam__off"></i>
                </button>
                <div class="vertical-divider"></div>
                <button id="js-leave-button" 
                    class="meeting-control-button meeting-control-button__leave-session">
                    <i id="js-leave-session-icon" class="fas fa-phone"></i>
                </button>
            </div>
        </div>
        <!-- Ending view -->
        <div id="js-end-view" class="container ending-view hidden">
            <h1>You have successfully left the session!</h1>
        </div>
    </div>
</body>
<script>


const VideoSDK = window.WebVideoSDK.default

const VideoQuality=window.WebVideoSDK.default
const client = VideoSDK.createClient()
//resource url was preloaded but not used within firsst few seconds make sure it has an appropiated 'as' value and it is preloaded intentionally
//A preload for 'https://source.zoom.us/videosdk/1.7.0/lib/js_media.min.js' is found, but is not used because the request credentials mode does not match. Consider taking a look at crossorigin attribute.
//ScriptProcessorNode is deprecated, use AudioWorklet instead 
client.init('en-US', 'CDN')

let stream
let noofusers=3
/*
perms = {
headers: {
  'Access-Control-Allow-Origin': "*",
  'Cross-Origin-Resource-Policy': "cross-origin",
  'Cross-Origin-Embedder-Policy': "credentialless",
  'Cross-Origin-Opener-Policy': "unsafe-none"
}
}
//did nothing, but this has to be the right way
*/
   let sdkKey= 'c1AZcLpgiw5lLaf3b616dKPM4gPal1qV4THu'
  let  sdkSecret= 'xSDP7mZxtLivrlj3LldVUuiubkATcQQbsXK2'
   let topic= 'test'
  let  password= '12345'
  let  name= 'test123'
 let   sessionKey= ''
  let  user_identity= ''
function generateSessionToken(
    sdkKey,
    sdkSecret,
    topic,
    passWord =  '',
    sessionKey = '',
    userIdentity ='',
    roleType = 1,
) {
    let signature = '';
    try {
        const iat = Math.round(new Date().getTime() / 1000);
        const exp = iat + 60 * 60 * 2;

        const oHeader = {alg: 'HS256', typ: 'JWT'};
        const oPayload = {
            app_key: sdkKey,
            iat,
            exp,
             tpc: topic,
             pwd: passWord,
             user_identity: userIdentity,
             session_key: sessionKey,
             role_type: roleType,
        };

        const sHeader = JSON.stringify(oHeader);
        const sPayload = JSON.stringify(oPayload);
        signature = KJUR.jws.JWS.sign('HS256', sHeader, sPayload, sdkSecret);
    } catch (e) {
        console.error(e);
    }
    return signature;
}
//Mangle this lines into working code
function isSupportWebCodecs(){
  return typeof MediaStreamTrackProcessor === 'function'
}
function isAndroidBrowser(){
  return /android/i.test(navigator.userAgent);
}
function isSupportOffscreenCanvas(){
  return typeof OffscreenCanvas === 'function';
}

 const PREVIEW_VIDEO_ELEMENT = document.getElementById('js-preview-video');

 const PREVIEW_VIDEO_DIMS = {
    Width: 800,
    Height: 450,
};
 const VIDEO_CANVAS = document.getElementById('video-canvas');
 const SELF_VIDEO_ELEMENT = document.getElementById('self-video');
 const SELF_VIDEO_CANVAS = document.getElementById('self-video-canvas');
 const VIDEO_CANVAS_DIMS = {
    Width: 1280,
    Height: 640,
};

class SimpleState {
    constructor(){
        this.reset();
    }
    reset(){
        this.selfId = -1;
        this.participants = [];
        this.audioEncode = false;
        this.audioDecode = false;
        this.isStartedAudio = false;
    }
    resetParticipantId(){
        this.participants = [];
    }
}
new SimpleState();
const state = new SimpleState

let prevIsSelfVideoOn = false;
let prevIsParticipantVideoOn = false;

/*
 * Dimensions and offset need to be carefully set to render multiple streams on a 
 * single canvas. There are several things to keep in mind: 
 *      1) Maintaining 16:9 aspect ratio (or whatever most participants have)
 *      2) Setting suitable height/width based on the render canvas dimensions
 *      3) Setting the correct offset
 * 
 * For this demo, we have a simple example with only two video streams:
 * |------------------------------------------------------------------|
 * |                                |                                 |
 * |                                |                                 |
 * |          Participant           |              Self               |
 * |                                |                                 |
 * |                                |                                 |
 * |                                |                                 |
 * |------------------------------------------------------------------|
 * 
 * To achieve the above, the participant stream is rendered with no offset and a
 * width equal to `canvas_width / 2`. For height, while we would typically need 
 * to handle aspect ratio and vertical centering ourselves, the V-SDK automatically 
 * handles it -- so just pass the canvas height 
 * 
 * We do the exact same for the self stream, but now have an x-offset of 
 * `cavas_width / 2`
 * 
 * This simple example can be extended to larger numbers (3, 4, etc.) and 
 * dynamically adjusted based on the active number of participants! 
 */

 const toggleSelfVideo = async (mediaStream, isVideoOn) => {

  const isUsingVideoElementToStartVideo =
    typeof window.OffscreenCanvas === 'function' && !mediaStream.isSupportMultipleVideos();
	
  const isRenderingSingleVideoOnCanvas =
    typeof window.OffscreenCanvas !== 'function' && !mediaStream.isSupportMultipleVideos();
	
  if (typeof isVideoOn !== 'boolean' || prevIsSelfVideoOn === isVideoOn) {
    return;
  }
  const canvas = isRenderingSingleVideoOnCanvas ? SELF_VIDEO_CANVAS : VIDEO_CANVAS;
  if (isVideoOn) {
    if (isUsingVideoElementToStartVideo) {
      SELF_VIDEO_ELEMENT.style.display = 'block';
      SELF_VIDEO_ELEMENT.style.width = '50%';
      SELF_VIDEO_ELEMENT.style.left = '50%';
      await mediaStream.startVideo({ videoElement: SELF_VIDEO_ELEMENT });
	   
    } else {
      await mediaStream.startVideo();
      if (isRenderingSingleVideoOnCanvas) {
        SELF_VIDEO_CANVAS.style.display = 'block';
        SELF_VIDEO_CANVAS.style.width = '50%';
        SELF_VIDEO_CANVAS.style.height = '50%';
        SELF_VIDEO_CANVAS.style.left = '50%';
        SELF_VIDEO_CANVAS.style.top = '50%';
        SELF_VIDEO_CANVAS.style.transform = 'translateY(-50%)';
        await mediaStream.renderVideo(
          canvas,
          state.selfId,
          VIDEO_CANVAS_DIMS.Width / noofusers,
          VIDEO_CANVAS_DIMS.Height / noofusers,
          0,
          0,
          VideoQuality.Video_360P
        );
      } else {
        await mediaStream.renderVideo(
          canvas,
          state.selfId,
          VIDEO_CANVAS_DIMS.Width / noofusers,
          VIDEO_CANVAS_DIMS.Height,
          VIDEO_CANVAS_DIMS.Width / noofusers,
          0,
          VideoQuality.Video_360P
        );
      }
    }
  } else {
    await mediaStream.stopVideo();
    if (!isUsingVideoElementToStartVideo) {
      if (isRenderingSingleVideoOnCanvas) {
        SELF_VIDEO_CANVAS.style.display = 'none';
      }
      await mediaStream.stopRenderVideo(canvas, state.selfId);
    } else {
      SELF_VIDEO_ELEMENT.style.display = 'none';
    }
  }
  prevIsSelfVideoOn = isVideoOn;
};

 const toggleParticipantVideo = async (mediaStream, userId, isVideoOn) => {
  if (typeof isVideoOn !== 'boolean' || prevIsParticipantVideoOn === isVideoOn) {
    return;
  }

  if (isVideoOn) {
 
    await mediaStream.renderVideo(
      VIDEO_CANVAS,
      userId,
      VIDEO_CANVAS_DIMS.Width / noofusers,
      VIDEO_CANVAS_DIMS.Height,
      0,
      0,
      VideoQuality.Video_360P
    );
  } else {
    await mediaStream.stopRenderVideo(VIDEO_CANVAS, userId);
  }
  prevIsParticipantVideoOn = isVideoOn;
};
/**
 * Initializes the mic and webcam toggle buttons
 *
 * @param {VideoClient} zoomClient
 * @param {Stream} mediaStream
 */
const initButtonClickHandlers = async (zoomClient, mediaStream) => {
  const initMicClick = () => {
    const micButton = document.getElementById('js-mic-button');
    const micIcon = document.getElementById('js-mic-icon');

    let isMuted = true;
    let isButtonAlreadyClicked = false;
    if (!state.isStartedAudio) {
      micIcon.classList.remove('fa-microphone-slash');
      micIcon.classList.add('fa-headset');
    }

    const toggleMicButtonStyle = () => {
      micIcon.classList.toggle('fa-microphone');
      micIcon.classList.toggle('fa-microphone-slash');
      micButton.classList.toggle('meeting-control-button__off');
    };

    const toggleMuteUnmute = () => (isMuted ? mediaStream.muteAudio() : mediaStream.unmuteAudio());

    const isMutedSanityCheck = () => {
      const mediaStreamIsMuted = mediaStream.isAudioMuted();
      console.log('Sanity check: is muted? ', mediaStreamIsMuted);
      console.log('Does this match button state? ', mediaStreamIsMuted === isMuted);
    };

    const onClick = async (event) => {
      event.preventDefault();
      if (!isButtonAlreadyClicked) {
        // Blocks logic from executing again if already in progress
        isButtonAlreadyClicked = true;
        if (state.isStartedAudio) {
          try {
            isMuted = !isMuted;
            await toggleMuteUnmute();
            toggleMicButtonStyle();
            isMutedSanityCheck();
          } catch (e) {
            console.error('Error toggling mute', e);
          }

          isButtonAlreadyClicked = false;
        } else {
          try {
            if (state.audioDecode && state.audioEncode) {
              await mediaStream.startAudio();
              micIcon.classList.remove('fa-headset');
              if (mediaStream.isAudioMuted()) {
                micIcon.classList.add('fa-microphone-slash');
                isMuted = true;
              } else {
                micIcon.classList.add('fa-microphone');
                isMuted = false;
              }
              state.isStartedAudio = true;
              isButtonAlreadyClicked = false;
            } else {
              console.warn('Please wait until media workers are ready');
            }
          } catch (e) {
            console.error('Error start audio', e);
          }
        }
      } else {
        console.log('=== WARNING: already toggling mic ===');
      }
    };

    micButton.addEventListener('click', onClick);
  };

  // Once webcam is started, the client will receive an event notifying that a video has started
  // At that point, video should be rendered. The reverse is true for stopping video
  const initWebcamClick = () => {
    const webcamButton = document.getElementById('js-webcam-button');

    let isWebcamOn = false;
    let isButtonAlreadyClicked = false;

    const toggleWebcamButtonStyle = () => webcamButton.classList.toggle('meeting-control-button__off');

    const onClick = async (event) => {
      event.preventDefault();
      if (!isButtonAlreadyClicked) {
        // Blocks logic from executing again if already in progress
        isButtonAlreadyClicked = true;

        try {
          isWebcamOn = !isWebcamOn;
          await toggleSelfVideo(mediaStream, isWebcamOn);
          toggleWebcamButtonStyle();
        } catch (e) {
          isWebcamOn = !isWebcamOn;
          console.error('Error toggling video', e);
        }

        isButtonAlreadyClicked = false;
      } else {
        console.log('=== WARNING: already toggling webcam ===');
      }
    };

    webcamButton.addEventListener('click', onClick);
  };

  const initLeaveSessionClick = () => {
    const leaveButton = document.getElementById('js-leave-button');

    const onClick = async (event) => {
      event.preventDefault();
      try {
        await Promise.all([toggleSelfVideo(mediaStream, false), toggleParticipantVideo(mediaStream, false)]);
        await zoomClient.leave();
        switchSessionToEndingView();
      } catch (e) {
        console.error('Error leaving session', e);
      }
    };

    leaveButton.addEventListener('click', onClick);
  };

  initMicClick();
  initWebcamClick();
  initLeaveSessionClick();
};




const PARTICIPANT_CHANGE_TYPE = {
  ADD: 'add',
  REMOVE: 'remove',
  UPDATE: 'update'
};

const PEER_VIDEO_STATE_CHANGE_ACTION_TYPE = {
  Start: 'Start',
  Stop: 'Stop'
};

const onUserAddedListener = (zoomClient) => {
  zoomClient.on('user-added', (payload) => {
    console.log(`User added`, payload);

    state.participants = zoomClient.getAllUser();
  });
};

const onUserRemovedListener = (zoomClient) => {
  zoomClient.on('user-removed', (payload) => {
    console.log(`User removed`, payload);

    state.participants = zoomClient.getAllUser();
  });
};

const onUserUpdatedListener = (zoomClient) => {
  zoomClient.on('user-updated', (payload) => {
    console.log(`User updated`, payload);

    state.participants = zoomClient.getAllUser();
  });
};

const onPeerVideoStateChangedListener = (zoomClient, mediaStream) => {
  zoomClient.on('peer-video-state-change', async (payload) => {
    console.log('onPeerVideoStateChange', payload);
    const { action, userId } = payload;

    if (state.participants.findIndex((user) => user.userId === userId) === -1) {
      console.log('Detected unrecognized participant ID. Ignoring: ', userId);
      return;
    }

    if (action === PEER_VIDEO_STATE_CHANGE_ACTION_TYPE.Start) {
      toggleParticipantVideo(mediaStream, userId, true);
    } else if (action === PEER_VIDEO_STATE_CHANGE_ACTION_TYPE.Stop) {
      toggleParticipantVideo(mediaStream, userId, false);
    }
  });
};

const onMediaWorkerReadyListener = (zoomClient) => {
  zoomClient.on('media-sdk-change', (payload) => {
    const { action, type, result } = payload;
    if (type === 'audio' && result === 'success') {
      if (action === 'encode') {
        state.audioEncode = true;
      } else if (action === 'decode') {
        state.audioDecode = true;
      }
    }
  });
};

const initClientEventListeners = (zoomClient, mediaStream) => {
  onUserAddedListener(zoomClient);
  onUserRemovedListener(zoomClient, mediaStream);
  onUserUpdatedListener(zoomClient);
  onPeerVideoStateChangedListener(zoomClient, mediaStream);
  onMediaWorkerReadyListener(zoomClient);
  // The started video before join the session
  setTimeout(() => {
    const peerParticipants = state.participants.filter((user) => user.userId !== state.selfId);
    if (peerParticipants.length > 0 && peerParticipants[0].bVideoOn === true) {
      toggleParticipantVideo(mediaStream, peerParticipants[0].userId, true);
    }
  }, 3000);
};

const isSafari = /^((?!chrome|android).)*safari/i.test(navigator.userAgent);
/**
 * Creates a zoom video client, and uses it to join/start a video session. It:
 *      1) Creates a zoom client
 *      2) Initializes the zoom client
 *      3) Tries to join a session, grabbing its Stream once successful
 *      4) Initializes the zoom client's important "on" event listeners
 *          - Very important, as failing to do so ASAP can miss important updates
 *      5) Joins the audio stream on mute
 */
const joinSession = async (zmClient) => {
  // const videoSDKLibDir = '/lib';
  const zmClientInitParams = {
    language: 'en-US'
    // dependentAssets: `${window.location.origin}${videoSDKLibDir}`
  };
  const sessionToken = generateSessionToken(
   sdkKey,
    sdkSecret,
    topic,
    password,
    sessionKey
  );

    let mediaStream;

  const initAndJoinSession = async () => {
    await zmClient.init(zmClientInitParams.language, zmClientInitParams.dependentAssets);

    try {
      await zmClient.join(topic, sessionToken, name, password);
      mediaStream = zmClient.getMediaStream();
      state.selfId = zmClient.getSessionInfo().userId;
    } catch (e) {
      console.error(e);
    }
  };

  const startAudioMuted = async () => {
    await mediaStream.startAudio();
    state.isStartedAudio = true;
    if (!mediaStream.isAudioMuted()) {
      mediaStream.muteAudio();
    }
  };

    const join = async () => {
        console.log('======= Initializing video session =======');
        await initAndJoinSession();
        /**
         * Note: it is STRONGLY recommended to initialize the client listeners as soon as 
         * the session is initialized. Once the user joins the session, updates are sent to
         * the event listeners that help update the session's participant state.
         * 
         * If you choose not to do so, you'll have to manually deal with race conditions.
         * You should be able to call "zmClient.getAllUser()" after the app has reached 
         * steady state, meaning a sufficiently-long time
         */
        console.log('======= Initializing client event handlers =======');
        initClientEventListeners(zmClient, mediaStream);
        console.log('======= Starting audio muted =======');
        if (!isSafari) {
              await startAudioMuted();
            }

        console.log('======= Initializing button click handlers =======');
        await initButtonClickHandlers(zmClient, mediaStream);
        console.log('======= Session joined =======');
    };

    await join();
    return zmClient;
};
const initPreviewButtons = () => {
    VideoSDK.preloadDependentAssets();
    const zmClient = VideoSDK.createClient();
    const audioTrack = VideoSDK.createLocalAudioTrack();
    const videoTrack = VideoSDK.createLocalVideoTrack();
    let isPreviewAudioConnected = false;
    let isWebcamOn = false;
    const initPreviewAudioButtonClick = () => {
        const VOLUME_ANIMATION_INTERVAL_MS = 100;
        let volumeAnimation = null;
        let prevVolumeAnimationStyle = '';

        const micButton = document.getElementById('js-preview-mic-button');
        const micIcon = document.getElementById('js-preview-mic-icon');
        
        let isMuted = true;

        let isButtonAlreadyClicked = false;

        const toggleMicButtonStyle = () => {
            micIcon.classList.toggle('fa-microphone');
            micIcon.classList.toggle('fa-microphone-slash');
            micButton.classList.toggle('meeting-control-button__off');
            
            if (prevVolumeAnimationStyle) {
                micIcon.classList.toggle(prevVolumeAnimationStyle);
                prevVolumeAnimationStyle = '';
            }
        };

        const animateMicVolume = () => {
            const newVolume = audioTrack.getCurrentVolume();
            let newVolumeAnimationStyle = '';

            if (newVolume === 0) {
                newVolumeAnimationStyle = '';
            } else if (newVolume <= 0.1) {
                newVolumeAnimationStyle = 'mic-feedback__very-low';
            } else if (newVolume <= 0.2) {
                newVolumeAnimationStyle = 'mic-feedback__low';
            } else if (newVolume <= 0.3) {
                newVolumeAnimationStyle = 'mic-feedback__medium';
            } else if (newVolume <= 0.4) {
                newVolumeAnimationStyle = 'mic-feedback__high';
            } else if (newVolume <= 0.5) {
                newVolumeAnimationStyle = 'mic-feedback__very-high';
            } else {
                newVolumeAnimationStyle = 'mic-feedback__max';
            }

            if (prevVolumeAnimationStyle !== '') {
                micIcon.classList.toggle(prevVolumeAnimationStyle);
            }

            if (newVolumeAnimationStyle !== '') {
                micIcon.classList.toggle(newVolumeAnimationStyle);
            }
            prevVolumeAnimationStyle = newVolumeAnimationStyle;
        };

        const startVolumeAnimation = () => { 
            if (!volumeAnimation) {
                volumeAnimation = setInterval(animateMicVolume, VOLUME_ANIMATION_INTERVAL_MS);
            }
        };

        const endVolumeAnimation = () => {
            if (volumeAnimation) {
                clearInterval(volumeAnimation);
                volumeAnimation = null;
            }
        };

        const toggleMuteUnmute = () => {
            if (isMuted) {
                audioTrack.mute();
                endVolumeAnimation();
            } else {
                audioTrack.unmute();
                startVolumeAnimation();
            }
        };

        const onClick = async (event) => {
            event.preventDefault();
            if (!isButtonAlreadyClicked) {
                // Blocks logic from executing again if already in progress
                isButtonAlreadyClicked = true;
                
                try {
                    if (!isPreviewAudioConnected) {
                        await audioTrack.start();
                        isPreviewAudioConnected = true;
                    }
                    isMuted = !isMuted;
                    await toggleMuteUnmute();
                    toggleMicButtonStyle();
                } catch (e) {
                    console.error('Error toggling mute', e);
                }

                isButtonAlreadyClicked = false;
            } else {
                console.log('=== WARNING: already toggling mic ===');
            }
        };

        micButton.addEventListener("click", onClick);
    };

    const initVideoPreviewButtonClick = () => {
        const webcamButton = document.getElementById('js-preview-webcam-button');

        let isButtonAlreadyClicked = false;

        const toggleWebcamButtonStyle = () => webcamButton.classList.toggle('meeting-control-button__off');
        const togglePreviewVideo = async () => isWebcamOn ? videoTrack.start(PREVIEW_VIDEO_ELEMENT) : videoTrack.stop();

        const onClick = async (event) => {
            event.preventDefault();
            if (!isButtonAlreadyClicked) {
                // Blocks logic from executing again if already in progress
                isButtonAlreadyClicked = true;

                try {
                    isWebcamOn = !isWebcamOn;
                    await togglePreviewVideo();
                    toggleWebcamButtonStyle();
                } catch (e) {
                    isWebcamOn = !isWebcamOn;
                    console.error('Error toggling video preview', e);
                }

                isButtonAlreadyClicked = false;
            } else {
                console.log('=== WARNING: already toggling webcam ===');
            }
        };

        webcamButton.addEventListener("click", onClick);
    };

    const initJoinButtonClick = () => {
        const joinButton = document.getElementById('js-preview-join-button');
        let isButtonAlreadyClicked = false;

        const onClick = async (event) => {
            event.preventDefault();
            if (!isButtonAlreadyClicked) {
                // Blocks logic from executing again if already in progress
                isButtonAlreadyClicked = true;
                try {
                    if (isPreviewAudioConnected) {
                      audioTrack.stop();
                      isPreviewAudioConnected = false;
          }
          if (isWebcamOn) {
            videoTrack.stop();
                    }
                    switchPreviewToLoadingView();
                    await joinSession(zmClient);
                    switchLoadingToSessionView();
                } catch (e) {
                    console.error('Error joining session', e);
                }

                isButtonAlreadyClicked = false;
            } else {
                console.log('=== WARNING: already toggling webcam ===');
            }
        };

        joinButton.addEventListener("click", onClick);
    };

    initPreviewAudioButtonClick();
    initVideoPreviewButtonClick();
    initJoinButtonClick();
};
window.addEventListener('DOMContentLoaded', async () => {
  console.log('======= Initializing preview =======');
  await initPreviewButtons();
  console.log('======= Done initializing preview =======');
});
const Views = {
    Preview: document.getElementById('js-preview-view'),
    Loading: document.getElementById('js-loading-view'),
    Session: document.getElementById('js-video-view'),
    End: document.getElementById('js-end-view'),
}

 const switchPreviewToLoadingView = () => {
    Views.Preview.classList.toggle('hidden');
    Views.Loading.classList.toggle('hidden');
};

 const switchLoadingToSessionView = () => {
    Views.Loading.classList.toggle('hidden');
    Views.Session.classList.toggle('hidden');
};

 const switchSessionToEndingView = () => {
    Views.Session.classList.toggle('hidden');
    Views.End.classList.toggle('hidden');
};


</script
</html>